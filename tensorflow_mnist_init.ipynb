{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#고급\n",
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])  # 입력될 이미지\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])  # 계산해서 나온결과 \n",
    "\n",
    "W = tf.Variable(tf.zeros([784,10])) # tf.zeros # 784 x 10 행렬을 0으로 initialization 0에서 9까지 10 개필터\n",
    "b = tf.Variable(tf.zeros([10]))     # 10 차원 벡터 0으로 initialization\n",
    "#initializer=tf.contrib.layers.xavier_initializer)\n",
    "\n",
    "sess.run(tf.initialize_all_variables())\n",
    "y = tf.nn.softmax(tf.matmul(x,W) + b) # 정답 \n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#가중치 초기화 #\n",
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  #initial = tf.get_variable(\"W_conv1\",shape,initializer=tf.contrib.layers.xavier_initializer())\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "#합성곱(Convolution)과 풀링(Pooling)#############33#\n",
    "\n",
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "# \n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "##########################################################\n",
    "\n",
    "#첫 번째 컨볼루션 #\n",
    "#W_conv1 = weight_variable([5, 5, 1, 32]) #[x,y,입력채널, 출력채널 ]\n",
    "W_conv1 = tf.get_variable(\"W_conv1\",shape=[5,5,1,32],\n",
    "                          initializer=tf.contrib.layers.xavier_initializer())\n",
    "b_conv1 = bias_variable([32])\n",
    "x_image = tf.reshape(x, [-1,28,28,1])\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "\n",
    "#두 번째 컨볼루션#\n",
    "#W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "W_conv2 = tf.get_variable(\"W_conv2\",shape=[5,5,32,64],\n",
    "                          initializer=tf.contrib.layers.xavier_initializer())\n",
    "b_conv2 = bias_variable([64])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "#세 번째 컨볼루션#\n",
    "#W_conv3 = weight_variable([5, 5, 64, 128])\n",
    "W_conv3 = tf.get_variable(\"W_conv3\",shape=[5,5,64,128],\n",
    "                          initializer=tf.contrib.layers.xavier_initializer())\n",
    "b_conv3 = bias_variable([128])\n",
    "h_conv3 = tf.nn.relu(conv2d(h_pool2, W_conv3) + b_conv3)\n",
    "h_pool3 = max_pool_2x2(h_conv3)\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.04\n",
      "step 100, training accuracy 0.78\n",
      "step 200, training accuracy 0.92\n",
      "step 300, training accuracy 0.92\n",
      "step 400, training accuracy 0.96\n",
      "step 500, training accuracy 0.92\n",
      "step 600, training accuracy 1\n",
      "step 700, training accuracy 0.94\n",
      "step 800, training accuracy 0.94\n",
      "step 900, training accuracy 1\n",
      "test accuracy 0.9726\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#완전 연결 계층 (Fully-Connected Layer)#\n",
    "W_fc1 = weight_variable([4* 4 *128, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "h_pool3_flat = tf.reshape(h_pool3, [-1, 4*4*128])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool3_flat, W_fc1) + b_fc1)\n",
    "\n",
    "\n",
    "#드롭아웃 (Dropout)\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y_conv), reduction_indices=[1]))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "sess.run(tf.initialize_all_variables())\n",
    "for i in range(1000):\n",
    "  batch = mnist.train.next_batch(50)\n",
    "  if i%100 == 0:\n",
    "    train_accuracy = accuracy.eval(feed_dict={\n",
    "        x:batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "    print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "  train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "\n",
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={\n",
    "    x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
